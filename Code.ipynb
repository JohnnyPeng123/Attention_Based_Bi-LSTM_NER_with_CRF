{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“JPEN6856_COMP5046_Ass1.ipynb”的副本",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGHoy6KpQDfZ",
        "colab_type": "text"
      },
      "source": [
        "# COMP5046 Assignment 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34DVNKgqQY21",
        "colab_type": "text"
      },
      "source": [
        "# 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cWUxAQrGlq6",
        "colab_type": "text"
      },
      "source": [
        "## Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7C4snIcNl22",
        "colab_type": "code",
        "outputId": "aa5cc83a-aa53-49a7-ecb0-e8e55a77c7a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# Code to download file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "!pip install spacy\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import numpy as np\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "id = '1Q6DMPeMOIVaYHnmOwpwLX28Pfxu1Yxvg'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('test.csv')\n",
        "\n",
        "id = '1kCYpK73wTTA88yisgPUAE_5cUW5Cklwo'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('train.csv')\n",
        "\n",
        "id = '1ukoWnJdhEFIKYestcDchJ325k0y_qxni'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('val.csv')\n",
        "\n",
        "import pandas as pd\n",
        "df_train = pd.read_csv(\"train.csv\")\n",
        "df_val = pd.read_csv(\"val.csv\")\n",
        "df_test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "Sentence_train = df_train['Sentence'].tolist()\n",
        "NER_train = df_train['NER'].tolist()\n",
        "Sentence_val = df_val['Sentence'].tolist()\n",
        "NER_val = df_val['NER'].tolist()\n",
        "Sentence_test = df_test['Sentence'].tolist()\n",
        "NER_test = df_test['NER'].tolist()\n",
        "\n",
        "print(\"Training Sentence number:\",len(Sentence_train))\n",
        "print(\"Validation Sentence number:\",len(Sentence_val))\n",
        "print(\"Testing Sentence number:\",len(Sentence_test))"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.6.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (47.1.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n",
            "Training Sentence number: 3000\n",
            "Validation Sentence number: 700\n",
            "Testing Sentence number: 3684\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc0XsBSjA_4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download pre-trained BERT-encoded embedding with no pooling strategy, this might takes 5-15 mins depends on your internet speed\n",
        "id = '1Bi7EKphd_ubFXfZ-l18B4eXn08BoF0z4'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('train_bert_clean.npy')\n",
        "\n",
        "id = '1CH3m-lRw0sfmr1_Mkz6vhrWuVjlZ7iib'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('val_bert_clean.npy')\n",
        "\n",
        "id = '1B6zzTW10MYeQWO4eaHZ68D1w6Rsb2QR3'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('test_bert_clean.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "431t6ATATZRk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_bert_clean = np.load('train_bert_clean.npy',allow_pickle=True)\n",
        "val_bert_clean = np.load('val_bert_clean.npy',allow_pickle=True)\n",
        "test_bert_clean = np.load('test_bert_clean.npy',allow_pickle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9VCD0wsMyjd9"
      },
      "source": [
        "## Tokenization & Feature Extraction with Spacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lMbD7zYZgLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "nlp.tokenizer = Tokenizer(nlp.vocab)\n",
        "\n",
        "def preprocess(data):\n",
        "  sent_id = []\n",
        "  lemma = []\n",
        "  pos = []\n",
        "  dep = []\n",
        "  ent = []\n",
        "  \n",
        "  for i in range(len(data)):\n",
        "    data_temp = data[i]\n",
        "    sent_id.append(i)\n",
        "    lemma_temp = []\n",
        "    pos_temp = []\n",
        "    dep_temp = []\n",
        "    ent_temp = []\n",
        "    \n",
        "    for w in nlp(data_temp):\n",
        "      lemma_temp.append(w.lemma_)\n",
        "      pos_temp.append(w.tag_)\n",
        "      dep_temp.append(w.dep_)\n",
        "      ent_temp.append(w.ent_type_)\n",
        "    \n",
        "    lemma.append(lemma_temp)\n",
        "    pos.append(pos_temp)\n",
        "    dep.append(dep_temp)\n",
        "    ent.append(ent_temp)\n",
        "      \n",
        "  return sent_id, lemma, pos, dep, ent\n",
        "\n",
        "train_sent_id, train_sent, train_pos, train_dep, train_ent = preprocess(Sentence_train)\n",
        "val_sent_id, val_sent, val_pos, val_dep, val_ent = preprocess(Sentence_val)\n",
        "test_sent_id, test_sent, test_pos, test_dep, test_ent = preprocess(Sentence_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9gBSgBCQh24",
        "colab_type": "text"
      },
      "source": [
        "## 2 - Input Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Firu0a5BXa9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Map words & NER Tags to index\n",
        "\n",
        "word_to_ix = {}\n",
        "for sentence in train_sent+val_sent+test_sent:\n",
        "    for word in sentence:\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "word_list = list(word_to_ix.keys())\n",
        "\n",
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "tag_to_ix = {START_TAG:0, STOP_TAG:1}\n",
        "for tags in NER_train+NER_val:\n",
        "    for tag in tags.split():\n",
        "        if tag not in tag_to_ix:\n",
        "            tag_to_ix[tag] = len(tag_to_ix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a0DVXjcJh0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Map additional features to index\n",
        "import numpy as np \n",
        "\n",
        "pos_to_ix = {}\n",
        "for sentence in train_pos+val_pos+test_pos:\n",
        "    for pos in sentence:\n",
        "        if pos not in pos_to_ix:\n",
        "            pos_to_ix[pos] = len(pos_to_ix)\n",
        "\n",
        "pos_embedding = np.eye(len(list(pos_to_ix.values())))\n",
        "\n",
        "dep_to_ix = {}\n",
        "for sentence in train_dep+val_dep+test_dep:\n",
        "    for dep in sentence:\n",
        "        if dep not in dep_to_ix:\n",
        "            dep_to_ix[dep] = len(dep_to_ix)\n",
        "\n",
        "dep_embedding = np.eye(len(list(dep_to_ix.values())))\n",
        "\n",
        "ent_to_ix = {}\n",
        "for sentence in train_ent+val_ent+test_ent:\n",
        "    for ent in sentence:\n",
        "        if ent not in ent_to_ix:\n",
        "            ent_to_ix[ent] = len(ent_to_ix)\n",
        "\n",
        "ent_embedding = np.eye(len(list(ent_to_ix.values())))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBaD8mQAP5dP",
        "colab_type": "code",
        "outputId": "5ccee6e3-e3dd-462f-9594-2a750f2e1e44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(pos_embedding.shape)\n",
        "print(dep_embedding.shape)\n",
        "print(ent_embedding.shape)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48, 48)\n",
            "(44, 44)\n",
            "(19, 19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlwFakT-lreY",
        "colab_type": "code",
        "outputId": "e2ee9818-4372-4360-93f0-3e8ca21ebbc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Generate Word Embedding Matrix\n",
        "import numpy as np\n",
        "import gensim.downloader as api\n",
        "word_emb_model = api.load(\"glove-twitter-50\") \n",
        "\n",
        "EMBEDDING_DIM = 50\n",
        "\n",
        "embedding_matrix = []\n",
        "for word in word_list:\n",
        "    try:\n",
        "        embedding_matrix.append(word_emb_model.wv[word])\n",
        "    except:\n",
        "        embedding_matrix.append([0]*EMBEDDING_DIM)\n",
        "embedding_matrix = np.array(embedding_matrix)\n",
        "embedding_matrix.shape"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12431, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJk9A7vTUgiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sum total embedding dimensions\n",
        "EMBEDDING_DIM = 50 # Glove word embedding size\n",
        "EMBEDDING_DIM = EMBEDDING_DIM + pos_embedding.shape[0] + dep_embedding.shape[0] + ent_embedding.shape[0] + 1024 # Bert Embedding has 1024 dimensions "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-vkGVmMl4Mx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convert Words, Tag, Additional Features to Index\n",
        "\n",
        "def to_index(data, to_ix):\n",
        "  if to_ix != tag_to_ix:\n",
        "    input_index_list = []\n",
        "    for sent in data:\n",
        "        input_index_list.append([to_ix[w] for w in sent])\n",
        "    return input_index_list\n",
        "  else:\n",
        "    input_index_list = []\n",
        "    for sent in data:\n",
        "        input_index_list.append([to_ix[w] for w in sent.split()])\n",
        "    return input_index_list\n",
        "\n",
        "train_input_index =  to_index(train_sent,word_to_ix)\n",
        "train_output_index = to_index(NER_train,tag_to_ix)\n",
        "train_ent_index =  to_index(train_ent,ent_to_ix)\n",
        "train_dep_index = to_index(train_dep,dep_to_ix)\n",
        "train_pos_index =  to_index(train_pos,pos_to_ix)\n",
        "\n",
        "val_input_index = to_index(val_sent,word_to_ix)\n",
        "val_output_index = to_index(NER_val,tag_to_ix)\n",
        "val_ent_index =  to_index(val_ent,ent_to_ix)\n",
        "val_dep_index = to_index(val_dep,dep_to_ix)\n",
        "val_pos_index =  to_index(val_pos,pos_to_ix)\n",
        "\n",
        "test_input_index = to_index(test_sent,word_to_ix)\n",
        "test_ent_index =  to_index(test_ent,ent_to_ix)\n",
        "test_dep_index = to_index(test_dep,dep_to_ix)\n",
        "test_pos_index =  to_index(test_pos,pos_to_ix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIu_lkJwQ55g",
        "colab_type": "text"
      },
      "source": [
        "# 3 - NER model\n",
        "#BERT-Based Bi-LSTM CRF with Attention \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUmVnMG6U2BC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "def argmax(vec):\n",
        "    # return the argmax as a python int\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + \\\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, 50)\n",
        "        self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "        \n",
        "        self.pos_embeds = nn.Embedding(pos_embedding.shape[0], pos_embedding.shape[0])\n",
        "        self.pos_embeds.weight.data.copy_(torch.from_numpy(pos_embedding))\n",
        "        \n",
        "        self.dep_embeds = nn.Embedding(dep_embedding.shape[0], dep_embedding.shape[0])\n",
        "        self.dep_embeds.weight.data.copy_(torch.from_numpy(dep_embedding))\n",
        "        \n",
        "        self.ent_embeds = nn.Embedding(ent_embedding.shape[0], ent_embedding.shape[0])\n",
        "        self.ent_embeds.weight.data.copy_(torch.from_numpy(ent_embedding))\n",
        "        \n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=2, bidirectional=True,dropout=0.5)\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim*2, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "        self.dropout_lstm=nn.Dropout(p=0.5)\n",
        "        \n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(4, 1, self.hidden_dim // 2).to(device),\n",
        "                torch.randn(4, 1, self.hidden_dim // 2).to(device))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def attention(self,lstm_out,hidden_out):\n",
        "        hidden_out_t = torch.transpose(hidden_out,0,1)\n",
        "        hidden_out_t = torch.transpose(hidden_out,1,2)\n",
        "\n",
        "        hidden_out_t_1 = hidden_out_t   \n",
        "        hidden_out_1 = hidden_out   \n",
        "        \n",
        "        for i in range(lstm_out.size()[0]-1):\n",
        "          hidden_out_t = torch.cat((hidden_out_t, hidden_out_t_1), 0)\n",
        "          hidden_out = torch.cat((hidden_out, hidden_out_1), 0)\n",
        "        \n",
        "        attn_weights = F.softmax(torch.bmm(lstm_out, hidden_out_t),dim=-1)\n",
        "        #attn_weights = F.softmax(torch.bmm(lstm_out, hidden_out_t)/np.sqrt(self.hidden_dim),dim=-1)\n",
        "        \n",
        "        attn_output = torch.bmm(attn_weights, hidden_out)\n",
        "        concat_output = torch.cat((attn_output, lstm_out), 1)\n",
        "        return concat_output\n",
        "\n",
        "    def _get_lstm_features(self, sentence, ent, pos, dep, bert):\n",
        "        self.hidden = self.init_hidden()\n",
        "        \n",
        "        w_embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        e_embeds = self.ent_embeds(ent).view(len(ent), 1, -1)\n",
        "        p_embeds = self.pos_embeds(pos).view(len(pos), 1, -1)\n",
        "        d_embeds = self.dep_embeds(dep).view(len(dep), 1, -1)\n",
        "        b_embeds = bert.view(len(bert), 1, -1)\n",
        "        \n",
        "        embeds = torch.cat((w_embeds,e_embeds,p_embeds,d_embeds,b_embeds),2)  \n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        \n",
        "        hidden_out = torch.cat((self.hidden[0].view(2, 2, 1, -1)[1,0,:,:],self.hidden[0].view(2, 2, 1, -1)[1,1,:,:]),1)\n",
        "        hidden_out = hidden_out.unsqueeze(0)\n",
        "        \n",
        "        att_out = self.attention(lstm_out,hidden_out)\n",
        "        att_out = att_out.view(-1,self.hidden_dim*2)\n",
        "        \n",
        "        att_out = self.dropout_lstm(att_out)\n",
        "        lstm_feats = self.hidden2tag(att_out)\n",
        "        \n",
        "        #lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "        #lstm_feats = self.hidden2tag(lstm_out)\n",
        "        \n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags, ent, pos, dep, bert):\n",
        "        feats = self._get_lstm_features(sentence, ent, pos, dep, bert)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence, ent, pos, dep, bert):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence, ent, pos, dep, bert)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbT9aht9qbWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cal_acc(model, input_index, output_index, ent_index, pos_index, dep_index, bert_clean):\n",
        "\n",
        "  counter = 0\n",
        "  counter_all = 0\n",
        "  predicted_list = []\n",
        "  ground_truth = []\n",
        "  \n",
        "  for i, idxs in enumerate(input_index):\n",
        "    sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "    ent = torch.tensor(ent_index[i], dtype=torch.long).to(device)\n",
        "    pos = torch.tensor(pos_index[i], dtype=torch.long).to(device)\n",
        "    dep = torch.tensor(dep_index[i], dtype=torch.long).to(device)\n",
        "    bert = torch.tensor(bert_clean[i], dtype=torch.float).to(device)\n",
        "\n",
        "    _, predicted = model.forward(sentence_in, ent, pos, dep, bert)\n",
        "    for j in range(len(output_index[i])):\n",
        "      counter_all += 1\n",
        "      \n",
        "      predicted_list.append(predicted[j])\n",
        "      ground_truth.append(output_index[i][j])\n",
        "\n",
        "      if predicted[j] == output_index[i][j]:\n",
        "        counter += 1\n",
        "\n",
        "  accuracy = counter/counter_all\n",
        "\n",
        "  return ground_truth, predicted_list, accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zbDniNJTxwmK"
      },
      "source": [
        "#4 - Evaluation\n",
        "#a. Evaluation Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4-Kj2ylE79o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HIDDEN_DIM = 100\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "h0xz8-rpwVVW"
      },
      "source": [
        "#b. - Training & Evaluations result\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcMBk2TCC9XP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "1fcb74a8-c606-4866-d566-948986d4ba05"
      },
      "source": [
        "\"\"\"Each epoch will take about 6-7 minutes\"\"\"\n",
        "import datetime\n",
        "\n",
        "for epoch in range(10):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "        ent_index = train_ent_index[i]\n",
        "        dep_index = train_dep_index[i]\n",
        "        pos_index = train_pos_index[i]\n",
        "        bert = train_bert_clean[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "        bert = torch.tensor(bert, dtype=torch.float).to(device) \n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets, ent, pos, dep, bert)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index,train_ent_index,train_pos_index,train_dep_index, train_bert_clean)\n",
        "    _, _, val_acc = cal_acc(model,val_input_index,val_output_index,val_ent_index,val_pos_index,val_dep_index, val_bert_clean)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        ent_index = val_ent_index[i]\n",
        "        dep_index = val_dep_index[i]\n",
        "        pos_index = val_pos_index[i]\n",
        "        bert = val_bert_clean[i]\n",
        "\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "        bert = torch.tensor(bert, dtype=torch.float).to(device) \n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets, ent, pos, dep, bert)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1, Training loss: 11103.50, train acc: 0.9503, val loss: 1333.60, val acc: 0.9385, time: 355.72s\n",
            "Epoch:2, Training loss: 5254.47, train acc: 0.9690, val loss: 1043.27, val acc: 0.9490, time: 353.10s\n",
            "Epoch:3, Training loss: 3836.85, train acc: 0.9786, val loss: 865.99, val acc: 0.9591, time: 353.22s\n",
            "Epoch:4, Training loss: 2973.44, train acc: 0.9804, val loss: 1008.00, val acc: 0.9483, time: 354.35s\n",
            "Epoch:5, Training loss: 2506.35, train acc: 0.9833, val loss: 1052.37, val acc: 0.9529, time: 353.85s\n",
            "Epoch:6, Training loss: 2208.91, train acc: 0.9882, val loss: 907.00, val acc: 0.9665, time: 355.12s\n",
            "Epoch:7, Training loss: 1862.90, train acc: 0.9907, val loss: 855.11, val acc: 0.9666, time: 354.11s\n",
            "Epoch:8, Training loss: 1881.03, train acc: 0.9906, val loss: 938.14, val acc: 0.9606, time: 352.91s\n",
            "Epoch:9, Training loss: 1618.85, train acc: 0.9927, val loss: 817.37, val acc: 0.9714, time: 354.91s\n",
            "Epoch:10, Training loss: 1728.92, train acc: 0.9921, val loss: 863.66, val acc: 0.9745, time: 357.04s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0YKFVXTy6Sk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "bd558cbd-2c65-4cf1-9594-a853751fea50"
      },
      "source": [
        "# Save model\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "torch.save(model, '/content/drive/My Drive/BERT_Bi-LSTM_CRF_w_Attention.pt')"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type BiLSTM_CRF. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_tNmktUnwgQt"
      },
      "source": [
        "#5 - Output & save test predictions to Kaggle required format \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3OKaBMo8Mtz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create function for create prediciton for the test set\n",
        "def predict_test(model, input_index, ent_index, pos_index, dep_index, bert_clean):\n",
        "\n",
        "  predicted_list = []\n",
        "  \n",
        "  for i, idxs in enumerate(input_index):\n",
        "    sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "    ent = torch.tensor(ent_index[i], dtype=torch.long).to(device)\n",
        "    pos = torch.tensor(pos_index[i], dtype=torch.long).to(device)\n",
        "    dep = torch.tensor(dep_index[i], dtype=torch.long).to(device)\n",
        "    bert = torch.tensor(bert_clean[i], dtype=torch.float).to(device)\n",
        "\n",
        "    _, predicted = model.forward(sentence_in, ent, pos, dep, bert)\n",
        "    for j in range(len(input_index[i])):\n",
        "      predicted_list.append(predicted[j])\n",
        "\n",
        "  return predicted_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Dn2DNvqBu5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make predictions for the test set and convert the predicted outputs to corresponding tags\n",
        "predicted_test_idx = predict_test(model,test_input_index,test_ent_index,test_pos_index,test_dep_index,test_bert_clean)\n",
        "\n",
        "predicted_test_tags = [] \n",
        "for i in range(len(predicted_test_idx)):\n",
        "  for tag, idx in tag_to_ix.items():\n",
        "      if idx == predicted_test_idx[i]:\n",
        "          predicted_test_tags.append(tag)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wihsuicK-o-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the predicted tags into required format for Kaggle submission \n",
        "df = pd.DataFrame({'Predicted': predicted_test_tags})\n",
        "df.to_csv('predictions.csv',index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}